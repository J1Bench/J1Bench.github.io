<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head>
  <meta charset="utf-8">
  <meta name="description" content="Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments</title>

  <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="css/bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer="" src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><i>Ready Jurist One:</i> Benchmarking Language Agents for Legal Intelligence in Dynamic Environments</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://akariasai.github.io/">Zheng Jia</a><sup>1†</sup></span>
            <span class="author-block">
              <a href="https://ellenmellon.github.io/">Shengbin Yue</a><sup>1†</sup></span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~yizhongw/">Wei Chen</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://research.ibm.com/people/avi-sil">Siyuan Wang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~hannaneh/">Yidong Liu</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~hannaneh/">Yun Song</a><sup>6*</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~hannaneh/">Zhongyu Wei</a><sup>12*</sup>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Fudan University,</span>
            <span class="author-block"><sup>2</sup>Shanghai Innovation Institute,</span>
            <span class="author-block"><sup>3</sup>Huazhong University of Science and Technology</span>
            <span class="author-block"><sup>4</sup>University of Southern California,</span>
            <span class="author-block"><sup>5</sup>Midu Technology,</span>
            <span class="author-block"><sup>6</sup>Northwest University of Political and Law</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.11511" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://github.com/AkariAsai/self-rag" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/selfrag/selfrag_train_data" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-images fa-w-18" aria-hidden="true" focusable="false" data-prefix="far" data-icon="images" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M480 416v16c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V176c0-26.51 21.49-48 48-48h16v48H54a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6v-10h48zm42-336H150a6 6 0 0 0-6 6v244a6 6 0 0 0 6 6h372a6 6 0 0 0 6-6V86a6 6 0 0 0-6-6zm6-48c26.51 0 48 21.49 48 48v256c0 26.51-21.49 48-48 48H144c-26.51 0-48-21.49-48-48V80c0-26.51 21.49-48 48-48h384zM264 144c0 22.091-17.909 40-40 40s-40-17.909-40-40 17.909-40 40-40 40 17.909 40 40zm-72 96l39.515-39.515c4.686-4.686 12.284-4.686 16.971 0L288 240l103.515-103.515c4.686-4.686 12.284-4.686 16.971 0L480 208v80H192v-48z"></path></svg><!-- <i class="far fa-images"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Data</span>
                </a>
              </span>
            </span></div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf"><b><i>J1-Bench</i></b></span> introduces six legal environments, which could be categorized into three levels of environmental complexity: Level I covers <b>Knowledge Questioning</b> and <b>Legal Consultation</b>; Level II includes <b>Complaint Drafting</b> and <b>Defence Drafting</b>; Level III involves <b>Civil Court</b> and <b>Criminal Court</b>.
      </h2>
      <iframe src="images/model.png" width="110%" height="518px"></iframe>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Summary</h2>
        <div class="content has-text-justified">
          <p><b>Misalignment between current benchmarks and realistic legal services</b><br>
          </p><p>A reliable evaluation system that identifies the gap between current LLM-based and ideal legal agents is necessary for the study of legal intelligence. However, existing benchmarks predominantly adopt static and non-interactive paradigms, failing to capture the dynamic and professional nature of real-world legal practice, which puts emphasis on <b>multi-turn interactions</b> and <b>procedrual legality</b>. The misalignment limits the understanding of language agents' capabilities in legal contexts.<br>
          <!-- <p> Can we train a model that can decide when to retrieve, judges if retrieved passages are indeed helpful and generates conditioned on them? Can we build a reliable instruction-following LM that can provide citations?</p> -->
          <p><b><i>J1-Envs:</i> open-ended legal environments of three levels of environmental complexity</b><br>
          </p><p>To this end, we present <i>J1-Envs</i>, open-ended legal environments that simulate realistic legal scenarios, where agents engage in multi-turn interactions with dynamic procedural legality. According to environmental complexity(<i>role diversity</i>, <i>interaction demands</i>, and <i>procedural difficulty</i>), the sixi environments are categorized into three levels:
            <ul>
              <li><span><b>Level-I</b> comprises knowledge questioning and legal consultation, where the legal agent answers the public's progressive questions on legal knowledge or specific cases.</li>
              <li><span><b>Level-II</b> involves complaint and defence drafting, where the legal agent provides step-by-step guidance to litigants in compliance with procedrual requirements, and systematically collects the necessary information to complete the drafting process.</li>
              <li><span><b>Level-III</b> consists of civil and criminal courts: within formal judicial processes, the legal agent facilitates interactions among parties, ensures procedural compliance, and produces legally valid judgments.</li>
            </ul>
            <br>
          </p>
          <p><b><i>J1-Eval:</i> task-specific and fine-grained metrics for agent capabilities evaluation</b><br>
          </p><p>Furthermore, we introduce <i>J1-Eval</i> to evaluate agent capabilities within our constructed environments with <b>task-specific</b> and <b>fine-grained</b> metrics. Extensive experiments reveal that while current agents have internalized legal knowledge, they still struggle to follow procedrual steps when performing tasks in dynamic environments, even the SOTA model(GPT-4o) fails to surpass the average score of 60.<br>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div></section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3"><i>J1-ENVS</i>: Interactive Legal Environments</h2>
        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Overall Model Performance</h3> -->
        <div class="content has-text-justified">
          <p>
          <span style="color: red"><i>J1-ENVS</i></span> encompasses six representative scenarios, which includes two parts: <b>(A) Role Agent Setting</b> leverages real-world legal sources and personality theories to construct different role agents; <b>(B) Multi-level Environment Construction</b> combines the various roles in specific procedures and relationships to form legal environments.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
        </div>
        <br>
        <div class="content has-text-justified">
          <h3 class="title is-4">Role Agent Setting</h3>
          <p>
          To simulate realistic legal scenarios, we extract different legal elements from real-world legal sources with GPT-4o. These elements are assigned to three levels of roles to mirror different groups of people seeking legal services: 
          <ul>
            <li><span><b><i>Type I: General Public</i></b> represents persons in various occupations, who seek knowledge-based or case-specific consultation.</li>
            <li><span><b><i>Type II: Specific Characters</i></b> have more explicit litigation needs, and are assigned more detailed information.</li>
            <li><span><b><i>Type III: Multi-specific Characters</i></b> hold specifc responsibilities within courtroom proceedings and are assigned real-world legal information corresponding to their roles.</li>
          </ul>
          </p>
        </div>
        <div class="content has-text-justified">
          <h3 class="title is-4">Multi-level Environment Construction</h3>
          <p>
          Building upon curated role sets, six representive legal environments are constructed and categorized into three levels by role diversity, interaction complexity, and preocedural depth.
          </p>
          <ul>
            <li><span><b>Level I: Knowledge Questioning(KQ) and Legal Consultation(LC).</b> This level involves two participants, where the general public initiates questions and the legal agent responds. The dialogue continues untill all questions are addressed. These scenarios aim to simulate the respons capabilities of the legal trainee in dynamic environments.</li>
            <li><span><b>Level II: Complaint Drafting(CD) and Defence Drafting(DD).</b> This level involves two participants: an individual with a specific legal need(i.e., drafting a legal document, such as a complaint or a defence), and a legal agent who guides the interaction to progressive collect the required information and ultimately generate a legal document. These scenarios aim to simulate the progress by which a practicing lawyer independently initiates and completes tasks based on a given agenda.</li>
            <li><span><b>Level III: Civil Court(CI) and Criminal Court(CR).</b> This level involves multiple participants and is governed by strict court procedural norms. Specifically, the judge agent oversees the courtroom process, which includes several stages, and guides other characters(Plaintiff's Lawyer & Defendant's Lawyer in Civil Court; Defendant & Lawyer, and the Procurator in Criminal Court) to reach a judgment.</li>
          </ul>
        </div>
        <div class="content has-text-justified">
          <h2 class="title is-4"><i>J1-Eval:</i> Holistic Legal Agent Evaluation</h2>
          <p>
          Given the distinct characteristics of each legal task, we design metrics accordingly.
          </p>
          <ul>
            <li><b>Level I</b> is characterised by two types of metrics. For binary questions where outputs of legal agents are summarized as "yes" or "no", <b>binary accuracy(BIN)</b> measures their accuracy by matching method. For non-binary questions, we leverage an LLM-based evaluation method to rate the original response of legal agents on a scale of 1 to 10 to form <b>non-binary score(NBIN)</b>.</li>

            <li><b>Level II</b> evaluates the quality of the generated legal doucument with two metrics: <b>Format-following score(FOR)</b> evaluates how closely the format of the generated legal document matches the reference. <b>Doucment score(DOC)</b> measures the average accuracy of each component of document with either matching or model-based method.</li>

            <li><b>Level III</b> evaluates the quality of the final judgment and procedural compliance, with two metrics: <b>Procedural-following score(PFS)</b> evaluates completeness of procedural stages through matching. <b>Judgment score(JUD)</b> evaluates the judgment quality with either model-based evaluation in civil courts or calculate deviation span in criminal courts. <b>Reason score(REA)</b> evaluates the judge inference based on ground truth in terms of legal points, logic, and factual accuracy. <b>Law accuracy(LAW)</b> measures law accuracy by matching based on ground truth.</li> 
          </ul>

        </div>
      </div></div></div></section>
      <section class="section">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Experiments</h2>
              <div class="columns is-vcentered interpolation-panel">
              </div>
              <br>
              <div class="content has-text-justified">
                <h3 class="title is-4">Performance among Various Legal Agents</h3>
                <h4 class = "title is-8">Overall Performance</h4>
                <p>
                  GPT-4o achieves the best performance, showing strong legal intelligence. Qwen3-Instruct-32B demonstrates performance beyond expectations, surpassing Deepseek series. Although the legal-specific LLMs perform comparably to the GPT series on existing legal benchmarks, they exhibit significantly weaker performance in our setting, falling behind even smaller models.
                </p>
                <img src="images\total_performance.png" alt="Overall Ranking">
                
                
                <h4 class ="title is-8">Performance at Level I, II, & III</h4>
                <p>
                  Both general and legal-specific models perform relatively well in Level I. However, their performance drop in Level II and level III, which requires proactive engagement and rigorous procedrual compliance.
                </p>
                <img src="images\main_result.png" alt="results">

                
                <h3 class="title is-8">Can LLMs drive <i>J1-ENVS</i>?</h3>
                <img src="images\behavioral_consistency.png" alt="Different NPC">
                <p>
                  Both GPT-4o and human rate the consistency between each role's profile and its behavior on a scale of 1 to 10. The ratings remain consistently high and stable, which validates the reliability and effectiveness of our environment. We then employ Qwen3-Instruct-32B to drive our environment, and find that the relative performance differences and rankings among agents remain consistent across various environments, further validating the robustness of our framework.
                </p>
                
                <img src="images\evaluation_evaluation_png.png" alt="Evaluation NPC">
                <h3 class="title is-8">Can LLMs serve as a fair evaluator?</h4>
                <p>
                  Both GPT-4o and human evaluators rate the result for a specific metric. Their scores largely(over 76%) remain consistent, and GPT-4o tends to rate lower scores than human evaluators. These results demonstrate the reliability and robustness of our evaluation framework, which enhances the validity of our findings about legal agents.
                </p>

              </div>
              
            </div></div></div></section>
      
      <section class="section">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Conclusion</h2>
              <p>
                <ul>
                  <li><b>(A)</b> This study introduces the first interactive and dynamic legal environment for agents. Our <b><i>J1-ENVS</i></b> covers six of the most representative real-world scenarios in Chinese legal practice.</li>
      
                  <li><b>(B)</b> We introduce <b><i>J1-EVAL</i></b> to perform fine-grained evaluation of agents across different levels of legal proficiency, ranging from trainee to lawyer to judge.</li>
      
                  <li><b>(C)</b> Experimental results reveal gaps between diverse agents and real-world legal demands, offering valuable insights to guide future progress.</li>
                  
                  <li><b>(D)</b> This work introduces a new paradigm for legal intelligence by shifting the focus from static evaluation to dynamic interaction. Beyond evaluation, it can further be extended for data generation and reinforcement learning training.</li>
                </ul>
              </p>
            </div>
          </div>
        </div>

      </section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{asai2023selfrag,
      author    = {Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
      title     = {{Self-RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},
      year      = {2023},
     journal    = {arXiv preprint arXiv:2310.11511},
     url        = {https://arxiv.org/abs/2310.11511}
    }</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
      <a class="icon-link" href="https://akariasai.github.io/" disabled="">
        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body></html>